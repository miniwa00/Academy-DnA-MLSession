{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQtzsd1I67fN"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdon0IFUpdgw"
   },
   "source": [
    "#### 완전연결계층에 의한 변환\n",
    "- 7개의 입력이 3개의 은닉층 뉴런에 대응되는 예\n",
    "- 간단한 예를 위해 가중치만 생각하고 편향은 생략함\n",
    "- 완전연결계층에 의한 변환의 파이썬 표현\n",
    " - 행렬곱은 np.matmul()로 구현\n",
    " - 입력 데이터 c는 2차원 데이터임 --> 추후 미니배치(여러 단어를 한꺼번에 학습) 처리를 고려함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tz8HKMeOpajF",
    "outputId": "5a632063-49cb-4e0b-c256-fdfb79fd4430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.70089616 -0.54695342  0.29417508]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])    # 입력데이터, 2차원, 추후 미니배치위한 확장성고려\n",
    "W = np.random.randn(7,3)           # 7*3 가중치행렬 랜덤\n",
    "h = np.matmul(c, W)                # 은닉 노드\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PNcl8Rgbpkxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.34751575 -0.05031772 -1.55552563]\n",
      " [-1.32448729 -0.08027747  1.52764905]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0],[0,0,1,0,0,0,0]])    \n",
    "W = np.random.randn(7,3)          \n",
    "h = np.matmul(c, W)               # [1,0,0,0,0,0,0]의 은닉, [0,0,1,0,0,0,0]의 은닉 구함\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "10_S8YlHprhJ"
   },
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "      def __init__(self, W): #초기화\n",
    "          self.params = [W]\n",
    "          self.grads = [np.zeros_like(W)]\n",
    "          self.x = None\n",
    "\n",
    "      def forward(self, x): # 순방향 추론\n",
    "          W, = self.params\n",
    "          out = np.dot(x, W)\n",
    "          self.x = x\n",
    "          return out\n",
    "\n",
    "      def backward(self, dout): #역방향 기능\n",
    "          W, = self.params\n",
    "          dx = np.dot(dout, W.T)\n",
    "          dW = np.dot(self.x.T, dout)\n",
    "          print(dW, self.grads[0][...])\n",
    "          self.grads[0][...] = dW\n",
    "          print(self.grads[0])\n",
    "          return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO3DDlUdpukY",
    "outputId": "fbdf4921-83b9-4231-d3ee-5ad2c3c7dbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67144698  0.65719715 -0.2256524 ]]\n",
      "[[-0.67144698  0.65719715 -0.2256524 ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[-0.67144698  0.65719715 -0.2256524 ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]\n",
      " [-0.          0.         -0.        ]]\n",
      "[[ 0.93366814 -1.06815424  1.09068492 -0.94194162  0.40194778 -0.25414866\n",
      "  -2.0250053 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])    # 입력\n",
    "W = np.random.randn(7,3)           # 가중치 랜덤\n",
    "layer = MatMul(W)                  # W 가중치를 사용하여 layer 객체 생성\n",
    "h = layer.forward(c)               # layer 객체의 순전파 수행 결과 --> 은닉 노드\n",
    "print(h)\n",
    "h = layer.backward(h)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2TR-32bJJyh",
    "outputId": "932ac63d-6d02-423f-e160-f34a92eb802a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.zeros_like(W)][0][...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0qEx6hKGhEF"
   },
   "source": [
    "####  CBOW 모델을 통한 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rm43DGWoGhEF",
    "outputId": "bb9f20d4-6ea7-4e35-8962-911addce787c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.08177886 -1.26480394 -0.97266214  1.97584378  1.8306013  -1.17231628\n",
      "  -0.36268982]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 샘플 맥락 데이터\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]]) #input  좌측\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]]) #input  우측\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)           # 두 입력의 출력인 hidden 값에 대한 평균\n",
    "\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USfGsjxuGhEG"
   },
   "source": [
    "#### 말뭉치 텍스트를 단어 ID로 변환\n",
    "- 미리 구현한 preprocess() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N2y41ecLGhEG"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id) # int 값\n",
    "            word_to_id[word] = new_id \n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LopIrnyvGhEG",
    "outputId": "4b9ec92c-988e-483b-a423-4cb3d60eed85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZR2lGm-GhEG"
   },
   "source": [
    "#### corpus로부터 맥락과 타겟 생성\n",
    "\n",
    "\n",
    "- create_contexts_target() 함수 정의\n",
    " - 입력: corpus, window_size (윈도우 크기가 1이면 좌우 한 단어씩 맥락에 포함)\n",
    " - 반환: 맥락, 타겟 (각각 넘파이 다차원 배열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QOj1bU9hGhEH"
   },
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOTpmebQGhEH",
    "outputId": "b9808f77-f494-4b22-b810-f10e84dce87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size = 1)\n",
    "#\n",
    "print(corpus)\n",
    "print(id_to_word)\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51HEIvbJGhEH"
   },
   "source": [
    "#### 맥락과 타겟의 one-hot 표현\n",
    "\n",
    "- convert_one_hot() 함수 사용\n",
    " - 입력: corpus, vocab_size (어휘 수)\n",
    " - 반환: 입력받은 corpus의 one-hot 표현 (각각 넘파이 다차원 배열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zLkOTNj2GhEH"
   },
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "  N = corpus.shape[0]\n",
    "  # 전체 문장의 길이 \n",
    "  if corpus.ndim == 1: # Label\n",
    "      one_hot = np.zeros((N, vocab_size), dtype=np.int32) # 7 X len(Vocab) or Vocab.nunique()\n",
    "      for idx, word_id in enumerate(corpus):\n",
    "          one_hot[idx, word_id] = 1  # 순서별로 몇번째 word 가 나왔는지\n",
    "\n",
    "  elif corpus.ndim == 2:  # Sentence , Input 이 쌍으로 들어가고 사이 단어를 예측하는 것이기 때문\n",
    "      C = corpus.shape[1]\n",
    "      one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "      for idx_0, word_ids in enumerate(corpus):\n",
    "          for idx_1, word_id in enumerate(word_ids):\n",
    "              one_hot[idx_0, idx_1, word_id] = 1\n",
    "\n",
    "  return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TupvLcfyGhEH"
   },
   "source": [
    "#### 학습 데이터 준비의 전체 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyWhNUACGhEH",
    "outputId": "17363f28-e201-40a7-9955-9891d5520e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size = 1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4hE0qvM7LX8"
   },
   "source": [
    "#### CBOW 모델을 통한 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xq3Ra8z7LX8",
    "outputId": "bb9f20d4-6ea7-4e35-8962-911addce787c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.52918199  2.12135303  2.46362898 -0.43470271  0.59349073 -3.57326261\n",
      "  -1.50627271]]\n"
     ]
    }
   ],
   "source": [
    "# 샘플 맥락 데이터\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]]) #input  좌측\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]]) #input  우측\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)           # 두 입력의 출력인 hidden 값에 대한 평균\n",
    "\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEcd0So1GhEI"
   },
   "source": [
    "#### SimpleCBOW 클래스의 구현 \n",
    "- common/SimpleCBOW.py\n",
    "- init, forward, backword 메서드로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynACvZKyGhEI"
   },
   "source": [
    "- 초기화 메서드\n",
    " - 인수로 어휘 수(vocab_size)와 은닉층 뉴런 수(hidden_size)를 받음\n",
    " - 가중치 2개 생성 (W_in, W_out)\n",
    " - 입력 MatMul 계층 2개, 출력 MatMul 계층 1개, Softmax with Loss 계층 1개 생성\n",
    "   - 입력 MatMul 계층은 맥락에서 사용하는 단어 수만큼 생성\n",
    " - 신경망에서 사용되는 모든 매개변수와 기울기를 모아두기 위한 params와 grads 리스트 생성\n",
    " - word_vecs에 단어 가중치 (즉 단어 벡터) 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JnGRcuO-GhEI"
   },
   "outputs": [],
   "source": [
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZpOBbEMGhEI"
   },
   "source": [
    "- 순전파 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YKKroQj_GhEI"
   },
   "outputs": [],
   "source": [
    "def forward(self, contexts, target):\n",
    "    h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "    h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "    h = (h0 + h1) * 0.5\n",
    "    score = self.out_layer.forward(h)\n",
    "    loss = self.loss_layer.forward(score, target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgE09J-pGhEI"
   },
   "source": [
    "- 역전파 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "p00-OOJbGhEI"
   },
   "outputs": [],
   "source": [
    "def backward(self, dout=1):\n",
    "    ds = self.loss_layer.backward(dout)\n",
    "    da = self.out_layer.backward(ds)\n",
    "    da *= 0.5\n",
    "    self.in_layer1.backward(da)\n",
    "    self.in_layer0.backward(da)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE1snjNu9ltL"
   },
   "source": [
    "### WV Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 71.7% 1191.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api # 1.6GB\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRu4EVO_9g9n"
   },
   "outputs": [],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAidpgud9kdn"
   },
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zhMaDWd9vKQ"
   },
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veof0FDP-E4h"
   },
   "source": [
    "### Word2Vec 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_k4DKV--G8H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "co80dm1e-P-d"
   },
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec(sentences = w2v_input,\n",
    "                        vector_size = 30,\n",
    "                        window = 3,\n",
    "                        min_count = 1,\n",
    "                        sg = 1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8hHgPhxEo7E"
   },
   "outputs": [],
   "source": [
    "wv = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxMfoDC6-QCn"
   },
   "outputs": [],
   "source": [
    "train_mean_vector = []\n",
    "\n",
    "for words in tqdm(train_data):\n",
    "        tmp = np.zeros(30)             # 다음 customer ID에 대한 vector를 계삲하기 전 0으로 초기화\n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            try:\n",
    "                tmp += w2v[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                pass\n",
    "        tmp /= cnt                      # customer ID 에 있는 아이템 갯수로 전체 벡터를 mean해줌  \n",
    "        train_mean_vector.append(tmp)\n",
    "        \n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8pU-zrRLOrS"
   },
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQh_EEscLQrn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "np.random.seed(100)\n",
    "num_data = 50\n",
    " \n",
    "x11 = np.linspace(0.3,0.7,20)\n",
    "x12 = np.linspace(1.3,1.8,15)\n",
    "x13 = np.linspace(2.4,3,15)\n",
    "x1 = np.concatenate((x11,x12,x13),axis=None)\n",
    "error = np.random.normal(1,0.5,num_data)\n",
    "x2 = 1.5*x1+2+error\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "fig.set_facecolor('white')\n",
    "plt.scatter(x1, x2, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK_Q1xo3LZmo"
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering(X, n_clusters, init_center=None, max_iter=10, epsilon=1e-4, random_state=100): \n",
    "    # inititalize centeroids\n",
    "    if init_center is None:\n",
    "        random.seed(random_state)\n",
    "        idx = random.sample(range(X.shape[0]), n_clusters)\n",
    "        center = X[idx,:]\n",
    "    else:\n",
    "        center = init_center\n",
    "    iteration = 1\n",
    "    # Center 지정 random하게\n",
    "    \n",
    "    labels_history = [] # label history \n",
    "    center_history = [] # centeroid history\n",
    "    while(iteration<=max_iter):\n",
    "        ## assign label\n",
    "        labels = []\n",
    "        for i in range(X.shape[0]):\n",
    "            data = X[i, :]\n",
    "            labels.append(np.argmin([np.linalg.norm(data-x) for x in center]))\n",
    "            # 가장 거리가 짧은 센터로의 할당\n",
    "        labels = np.array(labels)\n",
    "        ## update centeroids\n",
    "        next_center = []\n",
    "        print(labels,': Labels')\n",
    "        for i in range(n_clusters):\n",
    "            target_idx = np.where(labels==i)[0] # Label 이 i 인 데이터\n",
    "            center_val = np.mean(X[target_idx,:], axis=0) # 각 라벨의 좌표값들의 총 합, 평균이 구해진다. (X,Y 축 각각)\n",
    "            print(center_val,'중심평균값')\n",
    "            next_center.append(center_val)\n",
    " \n",
    "        next_center = np.array(next_center) # 각 평균값이 이동함.\n",
    "        if epsilon:\n",
    "            if np.linalg.norm(next_center-center) <= epsilon:\n",
    "                break\n",
    "        center = next_center\n",
    "        labels_history.append(labels)\n",
    "        center_history.append(center)\n",
    "        iteration += 1\n",
    "    return (labels, iteration, labels_history, center_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdXLmTy6LlOq"
   },
   "outputs": [],
   "source": [
    "X = np.stack([x1, x2], axis=1)\n",
    " \n",
    "init_center= np.array([[2,4],[1,5],[2.5,6]])\n",
    "max_iter=50\n",
    "epsilon=1e-10\n",
    "random_state=101\n",
    "n_clusters=3\n",
    "results = kmeans_clustering(X, n_clusters, init_center, max_iter, epsilon=1e-4, \n",
    "                           random_state=100)\n",
    "labels = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgI3pPbWLoPB"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "fig.set_facecolor('white')\n",
    "for i, label in enumerate(labels):\n",
    "    if label == 0:\n",
    "        color = 'blue'\n",
    "    elif label ==1:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'green'\n",
    "    plt.scatter(X[i,0],X[i,1], color=color)\n",
    "    \n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvVh5NhELrSL"
   },
   "outputs": [],
   "source": [
    "labels_history = results[2]\n",
    "for j, labels in enumerate(labels_history):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    fig.set_facecolor('white')\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 0:\n",
    "            color = 'blue'\n",
    "        elif label ==1:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'green'\n",
    "        plt.scatter(X[i,0],X[i,1], color=color)\n",
    "    plt.title(f'Iteration : {j+1}')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if86mA-RLt_D"
   },
   "source": [
    "### K-means 사이킷런"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8pLRqOGLwgo"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "kmeans = KMeans(n_clusters=3, init=init_center)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCH0jo9WLybU"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "fig.set_facecolor('white')\n",
    "for i, label in enumerate(labels):\n",
    "    if label == 0:\n",
    "        color = 'blue'\n",
    "    elif label ==1:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'green'\n",
    "    plt.scatter(X[i,0],X[i,1], color=color)\n",
    "    \n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jo8uVm3LzzB"
   },
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0UEEB_bL2d-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "labels = pd.DataFrame(iris.target)\n",
    "labels.columns=['labels']\n",
    "data = pd.DataFrame(iris.data)\n",
    "data.columns=['Sepal length','Sepal width','Petal length','Petal width']\n",
    "data = pd.concat([data,labels],axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4SyQL-XMGmD"
   },
   "outputs": [],
   "source": [
    "feature = data[ ['Sepal length','Sepal width','Petal length','Petal width']]\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7n6IdeHMJR6"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJkJreo8MMpu"
   },
   "outputs": [],
   "source": [
    "model = DBSCAN(min_samples=6)\n",
    "predict = pd.DataFrame(model.fit_predict(feature))\n",
    "predict.columns=['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYZGdA7fMON9"
   },
   "outputs": [],
   "source": [
    "r = pd.concat([feature,predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6wZJOd-MRNJ"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# scatter plot\n",
    "fig = plt.figure( figsize=(6,6))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(r['Sepal length'],r['Sepal width'],r['Petal length'],c=r['predict'],alpha=0.5)\n",
    "ax.set_xlabel('Sepal lenth')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Grm2eak7MT0r"
   },
   "outputs": [],
   "source": [
    "ct = pd.crosstab(data['labels'],r['predict'])\n",
    "print (ct)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
