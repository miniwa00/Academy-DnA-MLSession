{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972490b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738bdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('features_tr.csv',encoding='cp949')\n",
    "X_test = pd.read_csv('features_te.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4dcb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>...</th>\n",
       "      <th>occyp_type_v291</th>\n",
       "      <th>occyp_type_v292</th>\n",
       "      <th>occyp_type_v293</th>\n",
       "      <th>occyp_type_v294</th>\n",
       "      <th>occyp_type_v295</th>\n",
       "      <th>occyp_type_v296</th>\n",
       "      <th>occyp_type_v297</th>\n",
       "      <th>occyp_type_v298</th>\n",
       "      <th>occyp_type_v299</th>\n",
       "      <th>occyp_type_v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>-0.066787</td>\n",
       "      <td>-0.083388</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.098018</td>\n",
       "      <td>-0.113699</td>\n",
       "      <td>-0.144115</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.204744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.128239</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.220421</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.213867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027730</td>\n",
       "      <td>0.081860</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>-0.217725</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.134354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192803</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>-0.027709</td>\n",
       "      <td>-0.180056</td>\n",
       "      <td>0.022912</td>\n",
       "      <td>0.131015</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.101893</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.132544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027730</td>\n",
       "      <td>0.081860</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>-0.217725</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.134354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>2</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>-12079</td>\n",
       "      <td>-1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190977</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.179355</td>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.173492</td>\n",
       "      <td>0.082324</td>\n",
       "      <td>-0.027206</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.190396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-15291</td>\n",
       "      <td>-2475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>-0.066787</td>\n",
       "      <td>-0.083388</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.098018</td>\n",
       "      <td>-0.113699</td>\n",
       "      <td>-0.144115</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.204744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>-10082</td>\n",
       "      <td>-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190977</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.179355</td>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.173492</td>\n",
       "      <td>0.082324</td>\n",
       "      <td>-0.027206</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.190396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>-10145</td>\n",
       "      <td>-107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.128239</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.220421</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.213867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>-19569</td>\n",
       "      <td>-1013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033675</td>\n",
       "      <td>-0.103229</td>\n",
       "      <td>-0.003269</td>\n",
       "      <td>-0.068412</td>\n",
       "      <td>-0.092724</td>\n",
       "      <td>0.150945</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>-0.028494</td>\n",
       "      <td>0.192704</td>\n",
       "      <td>0.204878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 1567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       child_num  income_total  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  \\\n",
       "0              0      202500.0      -13899          -4709           1   \n",
       "1              1      247500.0      -11380          -1540           1   \n",
       "2              0      450000.0      -19087          -4434           1   \n",
       "3              0      202500.0      -15088          -2092           1   \n",
       "4              0      157500.0      -15037          -2105           1   \n",
       "...          ...           ...         ...            ...         ...   \n",
       "26452          2      225000.0      -12079          -1984           1   \n",
       "26453          1      180000.0      -15291          -2475           1   \n",
       "26454          0      292500.0      -10082          -2015           1   \n",
       "26455          0      171000.0      -10145           -107           1   \n",
       "26456          0       81000.0      -19569          -1013           1   \n",
       "\n",
       "       work_phone  phone  email  family_size  begin_month  ...  \\\n",
       "0               0      0      0          2.0          6.0  ...   \n",
       "1               0      0      1          3.0          5.0  ...   \n",
       "2               0      1      0          2.0         22.0  ...   \n",
       "3               0      1      0          2.0         37.0  ...   \n",
       "4               0      0      0          2.0         26.0  ...   \n",
       "...           ...    ...    ...          ...          ...  ...   \n",
       "26452           0      0      0          4.0          2.0  ...   \n",
       "26453           0      0      0          2.0         47.0  ...   \n",
       "26454           0      0      0          2.0         25.0  ...   \n",
       "26455           0      0      0          1.0         59.0  ...   \n",
       "26456           0      0      0          2.0          9.0  ...   \n",
       "\n",
       "       occyp_type_v291  occyp_type_v292  occyp_type_v293  occyp_type_v294  \\\n",
       "0            -0.089436         0.100895        -0.066787        -0.083388   \n",
       "1             0.043693         0.131514        -0.007164        -0.128239   \n",
       "2            -0.027730         0.081860         0.056325         0.053378   \n",
       "3            -0.192803         0.048254        -0.027709        -0.180056   \n",
       "4            -0.027730         0.081860         0.056325         0.053378   \n",
       "...                ...              ...              ...              ...   \n",
       "26452        -0.190977         0.165361         0.144755        -0.179355   \n",
       "26453        -0.089436         0.100895        -0.066787        -0.083388   \n",
       "26454        -0.190977         0.165361         0.144755        -0.179355   \n",
       "26455         0.043693         0.131514        -0.007164        -0.128239   \n",
       "26456         0.033675        -0.103229        -0.003269        -0.068412   \n",
       "\n",
       "       occyp_type_v295  occyp_type_v296  occyp_type_v297  occyp_type_v298  \\\n",
       "0             0.059916         0.098018        -0.113699        -0.144115   \n",
       "1            -0.021836         0.220421        -0.040256         0.082402   \n",
       "2             0.028166         0.134052         0.035300        -0.217725   \n",
       "3             0.022912         0.131015         0.031774         0.101893   \n",
       "4             0.028166         0.134052         0.035300        -0.217725   \n",
       "...                ...              ...              ...              ...   \n",
       "26452         0.039133         0.173492         0.082324        -0.027206   \n",
       "26453         0.059916         0.098018        -0.113699        -0.144115   \n",
       "26454         0.039133         0.173492         0.082324        -0.027206   \n",
       "26455        -0.021836         0.220421        -0.040256         0.082402   \n",
       "26456        -0.092724         0.150945         0.177361        -0.028494   \n",
       "\n",
       "       occyp_type_v299  occyp_type_v300  \n",
       "0             0.017819         0.204744  \n",
       "1             0.010280         0.213867  \n",
       "2             0.002053         0.134354  \n",
       "3             0.036992         0.132544  \n",
       "4             0.002053         0.134354  \n",
       "...                ...              ...  \n",
       "26452         0.124998         0.190396  \n",
       "26453         0.017819         0.204744  \n",
       "26454         0.124998         0.190396  \n",
       "26455         0.010280         0.213867  \n",
       "26456         0.192704         0.204878  \n",
       "\n",
       "[26457 rows x 1567 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9cf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26457, 1567) (10000, 1567) (26457, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9538e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>...</th>\n",
       "      <th>occyp_type_v291</th>\n",
       "      <th>occyp_type_v292</th>\n",
       "      <th>occyp_type_v293</th>\n",
       "      <th>occyp_type_v294</th>\n",
       "      <th>occyp_type_v295</th>\n",
       "      <th>occyp_type_v296</th>\n",
       "      <th>occyp_type_v297</th>\n",
       "      <th>occyp_type_v298</th>\n",
       "      <th>occyp_type_v299</th>\n",
       "      <th>occyp_type_v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>-21990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>-0.066787</td>\n",
       "      <td>-0.083388</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.098018</td>\n",
       "      <td>-0.113699</td>\n",
       "      <td>-0.144115</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.204744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>-18964</td>\n",
       "      <td>-8671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190977</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.179355</td>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.173492</td>\n",
       "      <td>0.082324</td>\n",
       "      <td>-0.027206</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.190396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>69372.0</td>\n",
       "      <td>-15887</td>\n",
       "      <td>-217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.128239</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.220421</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.213867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>-19270</td>\n",
       "      <td>-2531</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064925</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>-0.090608</td>\n",
       "      <td>-0.055061</td>\n",
       "      <td>0.155247</td>\n",
       "      <td>-0.065681</td>\n",
       "      <td>0.020824</td>\n",
       "      <td>-0.015149</td>\n",
       "      <td>0.152629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>-17822</td>\n",
       "      <td>-9385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027730</td>\n",
       "      <td>0.081860</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>-0.217725</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.134354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-18593</td>\n",
       "      <td>-5434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176133</td>\n",
       "      <td>-0.027530</td>\n",
       "      <td>-0.028341</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>-0.056716</td>\n",
       "      <td>0.085184</td>\n",
       "      <td>-0.063871</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.079299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-10886</td>\n",
       "      <td>-1315</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.128239</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.220421</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.213867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>-21016</td>\n",
       "      <td>-14018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153132</td>\n",
       "      <td>0.110237</td>\n",
       "      <td>0.125176</td>\n",
       "      <td>-0.019406</td>\n",
       "      <td>0.062362</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.070027</td>\n",
       "      <td>-0.100196</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>0.036069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-16541</td>\n",
       "      <td>-1085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>-0.066787</td>\n",
       "      <td>-0.083388</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.098018</td>\n",
       "      <td>-0.113699</td>\n",
       "      <td>-0.144115</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.204744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>-9154</td>\n",
       "      <td>-187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.131514</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>-0.128239</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>0.220421</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.213867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      child_num  income_total  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  \\\n",
       "0             0      112500.0      -21990              0           1   \n",
       "1             0      135000.0      -18964          -8671           1   \n",
       "2             0       69372.0      -15887           -217           1   \n",
       "3             0      112500.0      -19270          -2531           1   \n",
       "4             0      225000.0      -17822          -9385           1   \n",
       "...         ...           ...         ...            ...         ...   \n",
       "9995          0      202500.0      -18593          -5434           1   \n",
       "9996          0      202500.0      -10886          -1315           1   \n",
       "9997          0      292500.0      -21016         -14018           1   \n",
       "9998          0      180000.0      -16541          -1085           1   \n",
       "9999          0      270000.0       -9154           -187           1   \n",
       "\n",
       "      work_phone  phone  email  family_size  begin_month  ...  \\\n",
       "0              0      1      0          2.0         60.0  ...   \n",
       "1              0      1      0          2.0         36.0  ...   \n",
       "2              1      1      0          2.0         40.0  ...   \n",
       "3              1      0      0          2.0         41.0  ...   \n",
       "4              1      0      0          2.0          8.0  ...   \n",
       "...          ...    ...    ...          ...          ...  ...   \n",
       "9995           1      1      0          2.0         19.0  ...   \n",
       "9996           1      0      0          2.0         34.0  ...   \n",
       "9997           0      0      0          2.0         55.0  ...   \n",
       "9998           0      1      0          2.0         33.0  ...   \n",
       "9999           0      0      1          2.0         11.0  ...   \n",
       "\n",
       "      occyp_type_v291  occyp_type_v292  occyp_type_v293  occyp_type_v294  \\\n",
       "0           -0.089436         0.100895        -0.066787        -0.083388   \n",
       "1           -0.190977         0.165361         0.144755        -0.179355   \n",
       "2            0.043693         0.131514        -0.007164        -0.128239   \n",
       "3           -0.064925         0.053826         0.114095        -0.090608   \n",
       "4           -0.027730         0.081860         0.056325         0.053378   \n",
       "...               ...              ...              ...              ...   \n",
       "9995        -0.176133        -0.027530        -0.028341         0.032596   \n",
       "9996         0.043693         0.131514        -0.007164        -0.128239   \n",
       "9997        -0.153132         0.110237         0.125176        -0.019406   \n",
       "9998        -0.089436         0.100895        -0.066787        -0.083388   \n",
       "9999         0.043693         0.131514        -0.007164        -0.128239   \n",
       "\n",
       "      occyp_type_v295  occyp_type_v296  occyp_type_v297  occyp_type_v298  \\\n",
       "0            0.059916         0.098018        -0.113699        -0.144115   \n",
       "1            0.039133         0.173492         0.082324        -0.027206   \n",
       "2           -0.021836         0.220421        -0.040256         0.082402   \n",
       "3           -0.055061         0.155247        -0.065681         0.020824   \n",
       "4            0.028166         0.134052         0.035300        -0.217725   \n",
       "...               ...              ...              ...              ...   \n",
       "9995         0.184138        -0.056716         0.085184        -0.063871   \n",
       "9996        -0.021836         0.220421        -0.040256         0.082402   \n",
       "9997         0.062362         0.097417         0.070027        -0.100196   \n",
       "9998         0.059916         0.098018        -0.113699        -0.144115   \n",
       "9999        -0.021836         0.220421        -0.040256         0.082402   \n",
       "\n",
       "      occyp_type_v299  occyp_type_v300  \n",
       "0            0.017819         0.204744  \n",
       "1            0.124998         0.190396  \n",
       "2            0.010280         0.213867  \n",
       "3           -0.015149         0.152629  \n",
       "4            0.002053         0.134354  \n",
       "...               ...              ...  \n",
       "9995         0.149015         0.079299  \n",
       "9996         0.010280         0.213867  \n",
       "9997        -0.030441         0.036069  \n",
       "9998         0.017819         0.204744  \n",
       "9999         0.010280         0.213867  \n",
       "\n",
       "[10000 rows x 1567 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a8547",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac464d13",
   "metadata": {},
   "source": [
    "## lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc9dbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2d7ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LGBMClassifier(random_state=0), threshold='3.0*mean')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf = SelectFromModel(clf, threshold='3.0*mean')\n",
    "smf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec794e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_new = smf.transform(X_train)\n",
    "X_te_new = smf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fb6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selection_idx = smf.get_support()\n",
    "features_selection_name = X_train.columns[features_selection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "419cea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_new = pd.DataFrame(X_tr_new)\n",
    "X_te_new = pd.DataFrame(X_te_new)\n",
    "\n",
    "X_tr_new.columns = features_selection_name\n",
    "X_te_new.columns = features_selection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78da8472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [-0.7615 -0.7702 -0.7658 -0.7624 -0.7623]\n",
      "평균 검증 정확도: -0.7644\n",
      "log_loss: 0.7644468993145969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_tr_new, y_train, scoring='neg_log_loss', cv=5)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))\n",
    "print('log_loss:', -np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "580d5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_new.to_csv('sf_train.csv', index=False)\n",
    "X_te_new.to_csv('sf_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea781b",
   "metadata": {},
   "source": [
    "## tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61224d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 17:32:41,119]\u001b[0m A new study created in memory with name: no-name-4b9244b9-efdf-4948-8289-5ea9ad0642f5\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:33:51,991]\u001b[0m Trial 0 finished with value: -1.2505271884253926 and parameters: {'num_leaves': 56, 'min_child_samples': 95, 'max_depth': 35, 'learning_rate': 0.5259601136985205, 'n_estimators': 289, 'reg_lambda': 0.6144524198656093, 'reg_alpha': 0.3249226776884846}. Best is trial 0 with value: -1.2505271884253926.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:34:13,317]\u001b[0m Trial 1 finished with value: -1.013806457493774 and parameters: {'num_leaves': 75, 'min_child_samples': 55, 'max_depth': 5, 'learning_rate': 0.45296062113183266, 'n_estimators': 112, 'reg_lambda': 0.7469204970791506, 'reg_alpha': 0.1263265302331259}. Best is trial 1 with value: -1.013806457493774.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:35:17,279]\u001b[0m Trial 2 finished with value: -0.9569375249190083 and parameters: {'num_leaves': 71, 'min_child_samples': 85, 'max_depth': 7, 'learning_rate': 0.18706826562456674, 'n_estimators': 325, 'reg_lambda': 0.1519693569762105, 'reg_alpha': 0.21392504106683374}. Best is trial 2 with value: -0.9569375249190083.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:36:43,396]\u001b[0m Trial 3 finished with value: -1.0851571042460182 and parameters: {'num_leaves': 74, 'min_child_samples': 84, 'max_depth': 20, 'learning_rate': 0.22878837177307276, 'n_estimators': 357, 'reg_lambda': 0.909436955084031, 'reg_alpha': 0.5636849982044759}. Best is trial 2 with value: -0.9569375249190083.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:38:55,895]\u001b[0m Trial 4 finished with value: -0.8379101372424206 and parameters: {'num_leaves': 53, 'min_child_samples': 80, 'max_depth': 55, 'learning_rate': 0.0038559331345113562, 'n_estimators': 425, 'reg_lambda': 0.39272765472010784, 'reg_alpha': 0.015875913769030303}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:40:02,270]\u001b[0m Trial 5 finished with value: -1.281420240602016 and parameters: {'num_leaves': 71, 'min_child_samples': 50, 'max_depth': 34, 'learning_rate': 0.3419299582072049, 'n_estimators': 306, 'reg_lambda': 0.09235841696879632, 'reg_alpha': 0.47664543723651887}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:40:30,569]\u001b[0m Trial 6 finished with value: -0.9776871268673366 and parameters: {'num_leaves': 79, 'min_child_samples': 91, 'max_depth': 18, 'learning_rate': 0.3855815515507509, 'n_estimators': 99, 'reg_lambda': 0.871815742449592, 'reg_alpha': 0.5253366549028112}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:41:21,996]\u001b[0m Trial 7 finished with value: -1.0717481396910227 and parameters: {'num_leaves': 72, 'min_child_samples': 64, 'max_depth': 34, 'learning_rate': 0.23906224628430742, 'n_estimators': 220, 'reg_lambda': 0.2059199570352307, 'reg_alpha': 0.3714077160784439}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:42:59,537]\u001b[0m Trial 8 finished with value: -1.2467355178193091 and parameters: {'num_leaves': 62, 'min_child_samples': 75, 'max_depth': 37, 'learning_rate': 0.365841422725433, 'n_estimators': 451, 'reg_lambda': 0.5610648048514628, 'reg_alpha': 0.5582298733316151}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:44:12,229]\u001b[0m Trial 9 finished with value: -0.9491761567588473 and parameters: {'num_leaves': 69, 'min_child_samples': 74, 'max_depth': 51, 'learning_rate': 0.08703092176290962, 'n_estimators': 332, 'reg_lambda': 0.7460201325121542, 'reg_alpha': 0.3590053524719101}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:45:57,186]\u001b[0m Trial 10 finished with value: -0.9109359063308176 and parameters: {'num_leaves': 51, 'min_child_samples': 65, 'max_depth': 57, 'learning_rate': 0.025904832519340126, 'n_estimators': 473, 'reg_lambda': 0.3427469108850346, 'reg_alpha': 0.8891515178954268}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:48:03,078]\u001b[0m Trial 11 finished with value: -0.8635247285878004 and parameters: {'num_leaves': 50, 'min_child_samples': 66, 'max_depth': 60, 'learning_rate': 0.0030158135928267764, 'n_estimators': 478, 'reg_lambda': 0.38458056465538515, 'reg_alpha': 0.9156560784581639}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:49:33,509]\u001b[0m Trial 12 finished with value: -1.2897261165276304 and parameters: {'num_leaves': 50, 'min_child_samples': 67, 'max_depth': 60, 'learning_rate': 0.6337630879639489, 'n_estimators': 411, 'reg_lambda': 0.4017720124119418, 'reg_alpha': 0.9948198913267613}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:51:23,605]\u001b[0m Trial 13 finished with value: -0.8546066686562905 and parameters: {'num_leaves': 57, 'min_child_samples': 83, 'max_depth': 46, 'learning_rate': 0.00830170464524426, 'n_estimators': 410, 'reg_lambda': 0.3763953487194702, 'reg_alpha': 0.8110003355796254}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:52:44,667]\u001b[0m Trial 14 finished with value: -0.9538317280831885 and parameters: {'num_leaves': 58, 'min_child_samples': 83, 'max_depth': 46, 'learning_rate': 0.12312711339870126, 'n_estimators': 394, 'reg_lambda': 0.26354044269076143, 'reg_alpha': 0.7419072249078934}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:53:42,734]\u001b[0m Trial 15 finished with value: -0.8660560299332543 and parameters: {'num_leaves': 56, 'min_child_samples': 100, 'max_depth': 45, 'learning_rate': 0.09068820654446028, 'n_estimators': 225, 'reg_lambda': 0.49445836013189465, 'reg_alpha': 0.012289694815297729}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:55:15,638]\u001b[0m Trial 16 finished with value: -1.029425541815443 and parameters: {'num_leaves': 63, 'min_child_samples': 79, 'max_depth': 44, 'learning_rate': 0.16597307678738055, 'n_estimators': 417, 'reg_lambda': 0.47365201418138514, 'reg_alpha': 0.6812014295215209}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:57:06,732]\u001b[0m Trial 17 finished with value: -1.162582630901376 and parameters: {'num_leaves': 59, 'min_child_samples': 92, 'max_depth': 51, 'learning_rate': 0.28888175402622757, 'n_estimators': 497, 'reg_lambda': 0.025871598494333237, 'reg_alpha': 0.7342340956919791}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:58:05,331]\u001b[0m Trial 18 finished with value: -0.8997174874896773 and parameters: {'num_leaves': 54, 'min_child_samples': 74, 'max_depth': 54, 'learning_rate': 0.043493462509308786, 'n_estimators': 241, 'reg_lambda': 0.28461795381390964, 'reg_alpha': 0.08279759821363336}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 17:59:36,564]\u001b[0m Trial 19 finished with value: -1.5362757042972868 and parameters: {'num_leaves': 66, 'min_child_samples': 87, 'max_depth': 27, 'learning_rate': 0.6786125282956756, 'n_estimators': 375, 'reg_lambda': 0.66243082837679, 'reg_alpha': 0.2026864448534813}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:00:08,264]\u001b[0m Trial 20 finished with value: -0.902164996514025 and parameters: {'num_leaves': 53, 'min_child_samples': 79, 'max_depth': 40, 'learning_rate': 0.13297371248185494, 'n_estimators': 146, 'reg_lambda': 0.447362604088269, 'reg_alpha': 0.8189478050799528}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:02:07,203]\u001b[0m Trial 21 finished with value: -0.846842118880313 and parameters: {'num_leaves': 50, 'min_child_samples': 70, 'max_depth': 60, 'learning_rate': 0.0017308529437844956, 'n_estimators': 447, 'reg_lambda': 0.3560957764856878, 'reg_alpha': 0.9402804420176651}. Best is trial 4 with value: -0.8379101372424206.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:03:58,129]\u001b[0m Trial 22 finished with value: -0.8306149020494505 and parameters: {'num_leaves': 53, 'min_child_samples': 79, 'max_depth': 52, 'learning_rate': 0.003035616482513331, 'n_estimators': 420, 'reg_lambda': 0.32139614811733125, 'reg_alpha': 0.9836832123445423}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:05:27,785]\u001b[0m Trial 23 finished with value: -0.9358995907497114 and parameters: {'num_leaves': 53, 'min_child_samples': 71, 'max_depth': 54, 'learning_rate': 0.07946955389887325, 'n_estimators': 439, 'reg_lambda': 0.28900686946387577, 'reg_alpha': 0.985603022181553}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 18:07:05,313]\u001b[0m Trial 24 finished with value: -0.9139019608726258 and parameters: {'num_leaves': 60, 'min_child_samples': 79, 'max_depth': 50, 'learning_rate': 0.05338743924304145, 'n_estimators': 449, 'reg_lambda': 0.16979048169348407, 'reg_alpha': 0.6278228972072935}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:08:17,257]\u001b[0m Trial 25 finished with value: -1.0271361513189445 and parameters: {'num_leaves': 54, 'min_child_samples': 59, 'max_depth': 56, 'learning_rate': 0.17981612876755115, 'n_estimators': 356, 'reg_lambda': 0.5611629482509158, 'reg_alpha': 0.8752476685899889}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:09:37,335]\u001b[0m Trial 26 finished with value: -0.9753725735964913 and parameters: {'num_leaves': 52, 'min_child_samples': 71, 'max_depth': 41, 'learning_rate': 0.12021201381618976, 'n_estimators': 371, 'reg_lambda': 0.23719072189549556, 'reg_alpha': 0.44182086547011096}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:11:29,761]\u001b[0m Trial 27 finished with value: -0.8633552682111502 and parameters: {'num_leaves': 55, 'min_child_samples': 77, 'max_depth': 49, 'learning_rate': 0.007654980757702308, 'n_estimators': 435, 'reg_lambda': 0.3087513395347429, 'reg_alpha': 0.9431900339266522}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:12:25,753]\u001b[0m Trial 28 finished with value: -1.0228066377022609 and parameters: {'num_leaves': 61, 'min_child_samples': 70, 'max_depth': 28, 'learning_rate': 0.23305423052204952, 'n_estimators': 265, 'reg_lambda': 0.42134196592282885, 'reg_alpha': 0.8400325266191775}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:13:05,975]\u001b[0m Trial 29 finished with value: -1.2736555445642481 and parameters: {'num_leaves': 66, 'min_child_samples': 61, 'max_depth': 60, 'learning_rate': 0.5730491298328563, 'n_estimators': 173, 'reg_lambda': 0.5601951085548459, 'reg_alpha': 0.2771881775404305}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:14:56,115]\u001b[0m Trial 30 finished with value: -1.263472965053054 and parameters: {'num_leaves': 56, 'min_child_samples': 89, 'max_depth': 55, 'learning_rate': 0.4749129996458555, 'n_estimators': 496, 'reg_lambda': 0.0917509820295429, 'reg_alpha': 0.7466041130130594}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:16:26,597]\u001b[0m Trial 31 finished with value: -0.8923836932109822 and parameters: {'num_leaves': 57, 'min_child_samples': 81, 'max_depth': 47, 'learning_rate': 0.04237512633247413, 'n_estimators': 401, 'reg_lambda': 0.35737785988362786, 'reg_alpha': 0.8068836984099161}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:18:10,252]\u001b[0m Trial 32 finished with value: -0.8773056781871119 and parameters: {'num_leaves': 51, 'min_child_samples': 96, 'max_depth': 52, 'learning_rate': 0.0669965135163773, 'n_estimators': 463, 'reg_lambda': 0.3873508387669807, 'reg_alpha': 0.9987126272879143}. Best is trial 22 with value: -0.8306149020494505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:18:27,503]\u001b[0m Trial 33 finished with value: -0.8225713603853773 and parameters: {'num_leaves': 52, 'min_child_samples': 82, 'max_depth': 41, 'learning_rate': 0.021509267450949197, 'n_estimators': 54, 'reg_lambda': 0.5020734973660972, 'reg_alpha': 0.9353529106020352}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:18:42,790]\u001b[0m Trial 34 finished with value: -0.8586308839976564 and parameters: {'num_leaves': 52, 'min_child_samples': 86, 'max_depth': 41, 'learning_rate': 0.14866400246439282, 'n_estimators': 57, 'reg_lambda': 0.6018369137189744, 'reg_alpha': 0.9367416611031435}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:19:45,923]\u001b[0m Trial 35 finished with value: -0.9171698874298864 and parameters: {'num_leaves': 50, 'min_child_samples': 77, 'max_depth': 56, 'learning_rate': 0.103966722701879, 'n_estimators': 289, 'reg_lambda': 0.7026405124761117, 'reg_alpha': 0.640150157840841}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:21:02,197]\u001b[0m Trial 36 finished with value: -0.9083362401068973 and parameters: {'num_leaves': 54, 'min_child_samples': 69, 'max_depth': 14, 'learning_rate': 0.046885999511895475, 'n_estimators': 341, 'reg_lambda': 0.4922603249796996, 'reg_alpha': 0.8768070351488895}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:21:54,528]\u001b[0m Trial 37 finished with value: -0.9804213635784658 and parameters: {'num_leaves': 78, 'min_child_samples': 81, 'max_depth': 57, 'learning_rate': 0.19077036552356955, 'n_estimators': 179, 'reg_lambda': 0.8601740124700779, 'reg_alpha': 0.18999740292301992}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:22:12,706]\u001b[0m Trial 38 finished with value: -0.9363961815108265 and parameters: {'num_leaves': 52, 'min_child_samples': 73, 'max_depth': 28, 'learning_rate': 0.31084989897540355, 'n_estimators': 78, 'reg_lambda': 0.2002982626728389, 'reg_alpha': 0.42448671105457514}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:23:13,248]\u001b[0m Trial 39 finished with value: -1.2707365796041072 and parameters: {'num_leaves': 55, 'min_child_samples': 50, 'max_depth': 38, 'learning_rate': 0.40836639736297303, 'n_estimators': 299, 'reg_lambda': 0.5289569148384774, 'reg_alpha': 0.2996298877142026}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:23:42,547]\u001b[0m Trial 40 finished with value: -0.9724398839674094 and parameters: {'num_leaves': 64, 'min_child_samples': 55, 'max_depth': 31, 'learning_rate': 0.21093090238757944, 'n_estimators': 124, 'reg_lambda': 0.981585371679575, 'reg_alpha': 0.9373935888301623}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:25:29,940]\u001b[0m Trial 41 finished with value: -0.8309824109795046 and parameters: {'num_leaves': 58, 'min_child_samples': 83, 'max_depth': 43, 'learning_rate': 0.0043076142908708304, 'n_estimators': 424, 'reg_lambda': 0.3330389595488223, 'reg_alpha': 0.7893726094886478}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:27:15,040]\u001b[0m Trial 42 finished with value: -0.8563353368301044 and parameters: {'num_leaves': 58, 'min_child_samples': 89, 'max_depth': 43, 'learning_rate': 0.02171084777071912, 'n_estimators': 427, 'reg_lambda': 0.3332091637954838, 'reg_alpha': 0.8648492533742969}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:28:39,998]\u001b[0m Trial 43 finished with value: -0.9029179116420757 and parameters: {'num_leaves': 52, 'min_child_samples': 84, 'max_depth': 48, 'learning_rate': 0.07537950842833342, 'n_estimators': 386, 'reg_lambda': 0.24195199981249815, 'reg_alpha': 0.953056366199026}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:30:48,775]\u001b[0m Trial 44 finished with value: -0.8552551710393097 and parameters: {'num_leaves': 50, 'min_child_samples': 77, 'max_depth': 53, 'learning_rate': 0.00406951151253054, 'n_estimators': 474, 'reg_lambda': 0.4656333684440097, 'reg_alpha': 0.792759664934279}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:32:02,882]\u001b[0m Trial 45 finished with value: -0.875152174571426 and parameters: {'num_leaves': 55, 'min_child_samples': 81, 'max_depth': 36, 'learning_rate': 0.03911127597950414, 'n_estimators': 320, 'reg_lambda': 0.4347269503547508, 'reg_alpha': 0.9039180238609513}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:33:40,178]\u001b[0m Trial 46 finished with value: -0.9426748355812329 and parameters: {'num_leaves': 53, 'min_child_samples': 88, 'max_depth': 58, 'learning_rate': 0.10670759652965363, 'n_estimators': 464, 'reg_lambda': 0.1607369326869168, 'reg_alpha': 0.772591385595804}. Best is trial 33 with value: -0.8225713603853773.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:35:25,052]\u001b[0m Trial 47 finished with value: -0.8218311886559684 and parameters: {'num_leaves': 57, 'min_child_samples': 85, 'max_depth': 32, 'learning_rate': 0.002535699789956471, 'n_estimators': 360, 'reg_lambda': 0.3201684455423176, 'reg_alpha': 0.7028595396524745}. Best is trial 47 with value: -0.8218311886559684.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 18:36:46,999]\u001b[0m Trial 48 finished with value: -1.0849815335811805 and parameters: {'num_leaves': 61, 'min_child_samples': 93, 'max_depth': 31, 'learning_rate': 0.26807230178872105, 'n_estimators': 358, 'reg_lambda': 0.09829969484143045, 'reg_alpha': 0.6837620862215356}. Best is trial 47 with value: -0.8218311886559684.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 18:38:15,559]\u001b[0m Trial 49 finished with value: -0.9159552374630398 and parameters: {'num_leaves': 58, 'min_child_samples': 85, 'max_depth': 22, 'learning_rate': 0.07460695968627046, 'n_estimators': 422, 'reg_lambda': 0.3257121883235028, 'reg_alpha': 0.5616603627158078}. Best is trial 47 with value: -0.8218311886559684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8218311886559684 {'num_leaves': 57, 'min_child_samples': 85, 'max_depth': 32, 'learning_rate': 0.002535699789956471, 'n_estimators': 360, 'reg_lambda': 0.3201684455423176, 'reg_alpha': 0.7028595396524745}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def objective_lgbm(trial):\n",
    "    lgbm_random_state = 0\n",
    "    lgbm_n_jobs = -1\n",
    "    lgbm_num_leaves = trial.suggest_int(\"num_leaves\", 50, 80)\n",
    "    lgbm_min_child_samples = trial.suggest_int('min_child_samples',50,100)\n",
    "    lgbm_max_depth = trial.suggest_int('max_depth',5,60)\n",
    "    lgbm_learning_rate = trial.suggest_float('learning_rate',0.0001,0.7)\n",
    "    lgbm_n_estimators = trial.suggest_int('n_estimators',50,500)\n",
    "    lgbm_reg_lambda = trial.suggest_float('reg_lambda',0,1)\n",
    "    lgbm_reg_alpha = trial.suggest_float('reg_alpha',0,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    classifier_obj = LGBMClassifier(num_leaves = lgbm_num_leaves,\n",
    "                                    random_state = 0,\n",
    "                                    n_jobs = lgbm_n_jobs,\n",
    "                                    min_child_samples = lgbm_min_child_samples,\n",
    "                                    max_depth = lgbm_max_depth,\n",
    "                                    learning_rate = lgbm_learning_rate,\n",
    "                                    n_estimators = lgbm_n_estimators,\n",
    "                                    reg_lambda = lgbm_reg_lambda,\n",
    "                                    reg_alpha = lgbm_reg_alpha,\n",
    "                                    devie='gpu'\n",
    "                                   )\n",
    "    \n",
    "    score = cross_val_score(classifier_obj, X_train,  y_train, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "    logloss = score.mean()\n",
    "    return logloss\n",
    "\n",
    "study_lgbm = optuna.create_study(direction=\"maximize\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=50)\n",
    "print(study_lgbm.best_trial.value,study_lgbm.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aed0ba",
   "metadata": {},
   "source": [
    "-0.7347345617957105 {'num_leaves': 77, 'min_child_samples': 75, 'max_depth': 24, 'learning_rate': 0.05962509116013047, 'n_estimators': 234, 'reg_lambda': 0.30710121460984924, 'reg_alpha': 0.8263393436726127}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef99a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {'num_leaves': 77, 'min_child_samples': 75, 'max_depth': 24, 'learning_rate': 0.05962509116013047, 'n_estimators': 234, 'reg_lambda': 0.30710121460984924, 'reg_alpha': 0.8263393436726127}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce720f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_parmas_nfs =  {'num_leaves': 57, 'min_child_samples': 85, 'max_depth': 32, 'learning_rate': 0.002535699789956471, 'n_estimators': 360, 'reg_lambda': 0.3201684455423176, 'reg_alpha': 0.7028595396524745}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef913c",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058514fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.read_csv('../open/train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38df2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skf.split(train_org, train_org['credit']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480173e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6773d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000e+00,  2.0250e+05, -1.3899e+04, ...,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00],\n",
       "       [ 1.0000e+00,  2.4750e+05, -1.1380e+04, ...,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00],\n",
       "       [ 0.0000e+00,  2.0250e+05, -1.5088e+04, ...,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00],\n",
       "       ...,\n",
       "       [ 1.0000e+00,  1.8000e+05, -1.5291e+04, ...,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00],\n",
       "       [ 0.0000e+00,  2.9250e+05, -1.0082e+04, ...,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00],\n",
       "       [ 0.0000e+00,  8.1000e+04, -1.9569e+04, ...,  1.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da8e4aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.838808\tvalid_1's multi_logloss: 0.845755\n",
      "[200]\ttraining's multi_logloss: 0.811916\tvalid_1's multi_logloss: 0.825599\n",
      "[300]\ttraining's multi_logloss: 0.791652\tvalid_1's multi_logloss: 0.811996\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.838496\tvalid_1's multi_logloss: 0.848823\n",
      "[200]\ttraining's multi_logloss: 0.810837\tvalid_1's multi_logloss: 0.829653\n",
      "[300]\ttraining's multi_logloss: 0.790127\tvalid_1's multi_logloss: 0.816648\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.839125\tvalid_1's multi_logloss: 0.847737\n",
      "[200]\ttraining's multi_logloss: 0.811652\tvalid_1's multi_logloss: 0.828\n",
      "[300]\ttraining's multi_logloss: 0.791081\tvalid_1's multi_logloss: 0.814474\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.838752\tvalid_1's multi_logloss: 0.846596\n",
      "[200]\ttraining's multi_logloss: 0.810616\tvalid_1's multi_logloss: 0.826052\n",
      "[300]\ttraining's multi_logloss: 0.790101\tvalid_1's multi_logloss: 0.813082\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\hwangtaegyun\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.839402\tvalid_1's multi_logloss: 0.846747\n",
      "[200]\ttraining's multi_logloss: 0.811978\tvalid_1's multi_logloss: 0.825811\n",
      "[300]\ttraining's multi_logloss: 0.791923\tvalid_1's multi_logloss: 0.812138\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train1, X_valid1, y_train1, y_valid1 = X_train.iloc[train_idx].values, X_train.iloc[valid_idx].values,\\\n",
    "                                         train_org['credit'][train_idx].values, train_org['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(**lgbm_parmas_nfs, device = 'gpu')\n",
    "    lgb.fit(X_train1, y_train1, \n",
    "            eval_set=[(X_train1, y_train1), (X_valid1, y_valid1)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcca4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e7bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.iloc[:,1:]=0\n",
    "for fold in range(5):\n",
    "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(X_test)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a9771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('lgbm_test_submit_ensemble_w2v_nfs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bc3a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.209504</td>\n",
       "      <td>0.686112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.193326</td>\n",
       "      <td>0.688802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.106186</td>\n",
       "      <td>0.201997</td>\n",
       "      <td>0.691817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.112726</td>\n",
       "      <td>0.190159</td>\n",
       "      <td>0.697115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.126961</td>\n",
       "      <td>0.194572</td>\n",
       "      <td>0.678467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         0         1         2\n",
       "0  26457  0.104384  0.209504  0.686112\n",
       "1  26458  0.117872  0.193326  0.688802\n",
       "2  26459  0.106186  0.201997  0.691817\n",
       "3  26460  0.112726  0.190159  0.697115\n",
       "4  26461  0.126961  0.194572  0.678467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553082df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
